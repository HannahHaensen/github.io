<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hannah Schieber</title>

    <meta name="author" content="Hannah Schieber">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hannah Schieber, M. Sc.
                </p>
                <p> 
                  I am a PhD student at the Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander University Erlangen-Nürnberg (FAU). I am currently researching the topic of smart remote extended reality teleconsultation and product guidance under the supervision of Prof. Daniel Roth.
                </p>
                <p>
                  Prior that, I received my bachelor’s degree from HS Aalen, and my master’s degree from TH Ingolstadt, both in computer science. During my studies, I gained experience in the industry at MAPAL Dr. Kress KG, c-Com GmbH, Carl Zeiss AG and AUDI AG.

                </p>
                <p style="text-align:center">
                  <a href="mailto:hannah.schieber@fau.de">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=1tKoj0EAAAAJ&hl=de">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/hannah_haensen">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/HannahHaensen/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="https://hannahhaensen.github.io/assets/img/me.png"><img style="width:100%;max-width:100%" alt="profile photo" src="https://hannahhaensen.github.io/assets/img/me.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                    I am interested in computer vision, extended reality and in general in many things in life. Besides being passionate about my PhD studies I like to go cycling or go bouldering.
                </p>
              </td>
            </tr>
          </tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
			  <img width="160" src="https://user-images.githubusercontent.com/22636930/250825228-2340df9b-920a-4378-8fa1-956ba771fd79.png">
		</td>
     <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://camp-nerf.github.io/">
          <span class="papertitle">A Mixed Reality Guidance System for Blind and Visually Impaired People</span>
        </a>
        <br>
       Schieber, H., Kleinbeck, C., Pradel, C., Theelke, L., & Roth, D. 
             <br>
        <em>2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) (pp. 726-727). IEEE.</em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/9757681">IEEE</a>
        <p></p>
        <p>
        Persons affected by blindness or visual impairments are challenged by spatially understanding unfamiliar environments. To obtain such understanding, they have to sense their environment closely and carefully. Especially objects outside the sensing area of analog assistive devices, such as a white cane, are simply not perceived and can be the cause of collisions. This project proposes a mixed reality guidance system that aims at preventing such problems. We use object detection and the 3D sensing capabilities of a mixed reality head mounted device to inform users about their spatial surroundings.
        </p>
    </td>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website was originally created by: <a href="https://github.com/jonbarron/jonbarron_website">source code</a
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
